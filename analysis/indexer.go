package analysis

import (
	"bytes"
	"fmt"
	"go/ast"
	"go/parser"
	"go/printer"
	"go/token"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"sysevov2/models"
	"sysevov2/storage"
)

// RunParallelIndexing å¹¶å‘æ‰§è¡Œç´¢å¼•æ„å»º
// roots: æ ¹ç›®å½•åˆ—è¡¨ (e.g. ["./backend", "./frontend"])
// numThreads: å¹¶å‘åç¨‹æ•°
func RunParallelIndexing(roots []string, numThreads int) error {
	if numThreads <= 0 {
		numThreads = 1
	}

	var wg sync.WaitGroup
	// ä½¿ç”¨ç¼“å†² channel ä½œä¸ºä¿¡å·é‡é™åˆ¶å¹¶å‘åç¨‹æ•°
	semaphore := make(chan struct{}, numThreads)
	// ç”¨äºæ•è·å¹¶å‘è¿‡ç¨‹ä¸­çš„é”™è¯¯
	errChan := make(chan error, len(roots))

	fmt.Printf("ğŸš€ Starting parallel indexing with %d threads...\n", numThreads)

	for _, root := range roots {
		wg.Add(1)
		go func(path string) {
			defer wg.Done()

			// è·å–ä¿¡å·é‡ï¼ˆå¦‚æœè¾¾åˆ° numThreads åˆ™é˜»å¡ï¼‰
			semaphore <- struct{}{}
			defer func() { <-semaphore }() // é‡Šæ”¾ä¿¡å·é‡

			fmt.Printf("ğŸ§µ Thread processing: %s\n", path)

			if err := RunIncrementalIndexing(path); err != nil {
				fmt.Printf("âŒ Error indexing %s: %v\n", path, err)
				errChan <- err
			}
		}(root)
	}

	wg.Wait()
	close(errChan)

	if len(errChan) > 0 {
		return fmt.Errorf("parallel indexing completed with %d errors", len(errChan))
	}

	fmt.Println("âœ… Parallel indexing finished successfully.")
	return nil
}

// RunIncrementalIndexing æ‰§è¡Œå•ç›®å½•çš„å¢é‡ä»£ç åˆ†æä¸ç´¢å¼•æ„å»º
func RunIncrementalIndexing(projectRoot string) error {
	return filepath.Walk(projectRoot, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if info.IsDir() {
			// å¿½ç•¥å¸¸è§éä»£ç ç›®å½•
			if strings.HasPrefix(info.Name(), ".") || info.Name() == "vendor" || info.Name() == "node_modules" {
				return filepath.SkipDir
			}
			return nil
		}

		ext := filepath.Ext(path)
		if ext != ".go" && ext != ".ts" && ext != ".tsx" {
			return nil
		}

		// 2. å¢é‡æ£€æŸ¥ (Check Metadata)
		lastMod, _ := storage.FileMetaKey.HGet(path)
		if info.ModTime().Unix() <= lastMod {
			return nil // è·³è¿‡æœªä¿®æ”¹æ–‡ä»¶
		}

		fmt.Printf("ğŸ” Indexing: %s\n", path)

		// 3. è§£æä»£ç  (Parse)
		var chunks []*models.Chunk
		var parseErr error

		if ext == ".go" {
			chunks, parseErr = ParseGoFile(path)
		} else {
			// å‡è®¾ ParseTSFile åœ¨åŒåŒ…ä¸‹çš„ parser_ts_sidecar.go ä¸­å®šä¹‰
			chunks, parseErr = ParseTSFile(path)
		}

		if parseErr != nil {
			fmt.Printf("âš ï¸ Parse Error %s: %v\n", path, parseErr)
			return nil
		}

		// 4. å­˜å‚¨ä¸ç´¢å¼• (Store & Index)
		for _, chunk := range chunks {
			chunk.UpdatedAt = time.Now().Unix()

			// A. å­˜å‚¨ Chunk å†…å®¹ (Hash)
			if _, err := storage.ChunkStorage.HSet(chunk.ID, chunk); err != nil {
				fmt.Printf("âŒ DB Error: %v\n", err)
			}

			// B. ã€æ ¸å¿ƒä¿®å¤ã€‘å»ºç«‹åå‘ç´¢å¼• (Set: Symbol -> ChunkIDs)
			// è¿™ä½¿å¾— Selector å¯ä»¥é€šè¿‡ Symbol æ‰¾åˆ°å®šä¹‰å®ƒçš„ Chunk
			for _, symbol := range chunk.SymbolsDefined {
				if len(symbol) < 2 {
					continue
				}
				// å†™å…¥ Redis Set: sys/idx/sym/{symbol}
				if err := storage.Indexer.AddSymbolLink(symbol, chunk.ID); err != nil {
					fmt.Printf("âš ï¸ Index Error: %v\n", err)
				}
			}
		}

		// 5. æ›´æ–°å…ƒæ•°æ® (æ ‡è®°è¯¥æ–‡ä»¶å·²å¤„ç†)
		storage.FileMetaKey.HSet(path, info.ModTime().Unix())

		return nil
	})
}

// ParseGoFile è§£æå•ä¸ª Go æ–‡ä»¶å¹¶è¿”å› Chunks
func ParseGoFile(path string) ([]*models.Chunk, error) {
	content, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}

	fset := token.NewFileSet()
	node, err := parser.ParseFile(fset, path, content, parser.ParseComments)
	if err != nil {
		return nil, err
	}

	var chunks []*models.Chunk

	// éå† AST é¡¶çº§å£°æ˜
	for _, decl := range node.Decls {
		switch d := decl.(type) {
		case *ast.FuncDecl:
			// æå–å‡½æ•°æˆ–æ–¹æ³•
			chunks = append(chunks, extractGoFunc(d, fset, path, content))
		case *ast.GenDecl:
			// æå–ç±»å‹å®šä¹‰ (struct, interface)
			for _, spec := range d.Specs {
				if typeSpec, ok := spec.(*ast.TypeSpec); ok {
					chunks = append(chunks, extractGoType(d, typeSpec, fset, path, content))
				}
			}
		}
	}

	return chunks, nil
}

// extractGoFunc æå–å‡½æ•°/æ–¹æ³• Chunk
func extractGoFunc(fn *ast.FuncDecl, fset *token.FileSet, path string, content []byte) *models.Chunk {
	name := fn.Name.Name
	// å¤„ç† Receiver (æ–¹æ³•): User.Save
	if fn.Recv != nil && len(fn.Recv.List) > 0 {
		recvType := ""
		expr := fn.Recv.List[0].Type
		// å¤„ç†æŒ‡é’ˆ *User å’Œæ™®é€š User
		if star, ok := expr.(*ast.StarExpr); ok {
			if ident, ok := star.X.(*ast.Ident); ok {
				recvType = ident.Name
			}
		} else if ident, ok := expr.(*ast.Ident); ok {
			recvType = ident.Name
		}
		if recvType != "" {
			name = recvType + "." + name
		}
	}

	// æ„é€ å”¯ä¸€ ID: filepath:FunctionName
	id := fmt.Sprintf("%s:%s", path, name)

	// æå–å®Œæ•´ä»£ç  (Body)
	start := fset.Position(fn.Pos()).Offset
	end := fset.Position(fn.End()).Offset
	fullBody := string(content[start:end])

	// ç”Ÿæˆéª¨æ¶ (Skeleton)
	skeleton := generateGoSkeleton(fn, fset)

	return &models.Chunk{
		ID:                id,
		Type:              "Function",
		Skeleton:          skeleton,
		Body:              fullBody,
		SymbolsDefined:    []string{name},            // å®šä¹‰äº†è‡ªå·±
		SymbolsReferenced: extractGoSymbols(fn.Body), // å¼•ç”¨äº†åˆ«äºº
		FilePath:          path,
	}
}

// extractGoType æå–ç»“æ„ä½“/æ¥å£ Chunk
func extractGoType(decl *ast.GenDecl, spec *ast.TypeSpec, fset *token.FileSet, path string, content []byte) *models.Chunk {
	name := spec.Name.Name
	id := fmt.Sprintf("%s:%s", path, name)

	start := fset.Position(decl.Pos()).Offset
	end := fset.Position(decl.End()).Offset
	fullBody := string(content[start:end])

	return &models.Chunk{
		ID:                id,
		Type:              "Type",
		Skeleton:          fullBody, // å¯¹äº Typeï¼Œéª¨æ¶å³å…¨æ–‡
		Body:              fullBody,
		SymbolsDefined:    []string{name},
		SymbolsReferenced: extractGoSymbols(spec.Type), // æ‰«æå­—æ®µç±»å‹ä¾èµ–
		FilePath:          path,
	}
}

// generateGoSkeleton ç”Ÿæˆéª¨æ¶: æŠŠå‡½æ•°ä½“æç©ºï¼Œæ¢æˆ "..."
func generateGoSkeleton(fn *ast.FuncDecl, fset *token.FileSet) string {
	// æµ…æ‹·è´ AST èŠ‚ç‚¹ï¼Œé¿å…ä¿®æ”¹åŸç»“æ„å½±å“åç»­å¤„ç†
	tempFn := *fn
	// æ›¿æ¢å‡½æ•°ä½“ä¸ºä¸€ä¸ªç©ºçš„ BlockStmt
	tempFn.Body = &ast.BlockStmt{
		List: []ast.Stmt{
			&ast.ExprStmt{X: &ast.Ident{Name: "..."}}, // å ä½ç¬¦
		},
		Lbrace: fn.Body.Lbrace,
		Rbrace: fn.Body.Rbrace,
	}

	var buf bytes.Buffer
	printer.Fprint(&buf, fset, &tempFn)
	return buf.String()
}

// extractGoSymbols æå– AST èŠ‚ç‚¹ä¸­å¼•ç”¨çš„æ‰€æœ‰æ ‡è¯†ç¬¦
func extractGoSymbols(node ast.Node) []string {
	refs := make(map[string]struct{})
	if node == nil {
		return nil
	}

	// æ·±åº¦ä¼˜å…ˆéå† AST
	ast.Inspect(node, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.CallExpr:
			// æ•è·å‡½æ•°è°ƒç”¨: foo() -> foo
			if ident, ok := x.Fun.(*ast.Ident); ok {
				refs[ident.Name] = struct{}{}
			} else if sel, ok := x.Fun.(*ast.SelectorExpr); ok {
				// æ•è·æ–¹æ³•è°ƒç”¨: pkg.Foo() -> Foo, pkg
				refs[sel.Sel.Name] = struct{}{}
				if id, ok := sel.X.(*ast.Ident); ok {
					refs[id.Name] = struct{}{}
				}
			}
		case *ast.SelectorExpr:
			// æ•è·å±æ€§è®¿é—®: user.Name -> Name
			refs[x.Sel.Name] = struct{}{}
		case *ast.CompositeLit:
			// æ•è·ç»“æ„ä½“åˆå§‹åŒ–: &User{} -> User
			if ident, ok := x.Type.(*ast.Ident); ok {
				refs[ident.Name] = struct{}{}
			}
		case *ast.Ident:
			// å¤‡é€‰ç­–ç•¥ï¼šå¦‚æœéœ€è¦æ›´æ¿€è¿›çš„ç´¢å¼•ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š
			// refs[x.Name] = struct{}{}
		}
		return true
	})

	var list []string
	for k := range refs {
		// ç®€å•çš„å»å™ªï¼Œå¿½ç•¥å¤ªçŸ­çš„å˜é‡å
		if len(k) > 1 {
			list = append(list, k)
		}
	}
	return list
}
